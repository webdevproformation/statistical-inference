---
title: "P-values"
author: "Linda Angulo Lopez"
highlighter: highlight.js
hitheme: tomorrow
mode: selfcontained
subtitle: Statistical inference
framework: io2012
url:
  assets: ../../assets
  lib: ../../librariesNew
widgets: mathjax
---
```{r setup, cache = F, echo = F, message = F, warning = F, tidy = F}
# make this an external chunk that can be included in any file
options(width = 100)
knitr::opts_chunk$set(message = F, error = F, warning = F, comment = NA, fig.align = 'center', dpi = 100, tidy = F, cache.path = '.cache/', fig.path = 'fig/')

options(xtable.type = 'html')
knitr::knit_hooks$set(inline = function(x) {
  if(is.numeric(x)) {
    round(x, getOption('digits'))
  } else {
    paste(as.character(x), collapse = ', ')
  }
})
knitr::knit_hooks$set(plot = knitr:::hook_plot_html)
```

# P-values

You calculate a p value by calculating the probability of obtaining data as or more extreme than you actually obtained in favor of the alternative, where the probability calculation is done under the null. When communicating a P-value, the reader can perform the test at whatever Type I error rate that they would like. Just compare the P-value to the desired Type I error rate and if the P-value is smaller, reject the null hypothesis.

![https://xkcd.com/1132/](https://github.com/lindangulopez/statistical-inference/blob/master/DataAnalysis/P_values.png?raw=true)

Formally, the P-value is the probability of getting data as or more extreme than the observed data in favor of the alternative. The probability calculation is done assuming that the null is true. In other words if we get a very large T statistic the P-value answers the question "How likely would it be to get a statistic this large or larger if the null was actually true?". If the answer to that question is "very unlikely", in other words the P-value is very small, then it sheds doubt on the null being true, since you actually observed a statistic that extreme.


* Most common measure of "statistical significance"
* Their ubiquity, along with concern over their interpretation and use
  makes them controversial among statisticians
  * [http://warnercnr.colostate.edu/~anderson/thompson1.html](http://warnercnr.colostate.edu/~anderson/thompson1.html)
  * Also see *Statistical Evidence: A Likelihood Paradigm* by Richard Royall 
  * *Toward Evidence-Based Medical Statistics. 1: The P Value Fallacy* by Steve Goodman
  * The hilariously titled: *The Earth is Round (p < .05)* by Cohen.
* Some positive comments
  * [simply statistics](http://simplystatistics.org/2012/01/06/p-values-and-hypothesis-testing-get-a-bad-rap-but-we/)
  * [normal deviate](http://normaldeviate.wordpress.com/2013/03/14/double-misunderstandings-about-p-values/)
  * [Error statistics](http://errorstatistics.com/2013/06/14/p-values-cant-be-trusted-except-when-used-to-argue-that-p-values-cant-be-trusted/)

---


## What is a P-value? 

__Idea__: Suppose nothing is going on - how unusual is it to see the estimate we got?

__Approach__: 

1. Define the hypothetical distribution of a data summary (statistic) when "nothing is going on" (_null hypothesis_)
2. Calculate the summary/statistic with the data we have (_test statistic_)
3. Compare what we calculated to our hypothetical distribution and see if the value is "extreme" (_p-value_)

---
## P-values
* The P-value is the probability under the null hypothesis of obtaining evidence as extreme or more extreme than would be observed by chance alone
* If the P-value is small, then either $H_0$ is true and we have observed a rare event or $H_0$ is false
*  In our example the $T$ statistic was $0.8$. 
  * What's the probability of getting a $T$ statistic as large as $0.8$?
```{r}
pt(0.8, 15, lower.tail = FALSE) 
```
* Therefore, the probability of seeing evidence as extreme or more extreme than that actually obtained under $H_0$ is `r pt(0.8, 15, lower.tail = FALSE)`

Example:  imagine if you wanted to test mu = mu0 versus mu > mu0 and our T statistic work got to be 2.5 on 15 degrees of freedom. What is the probability of getting a T statistic as large as 2.5 under this, in this scenario?

```{r}
pt(2.5, 15, lower.tail = FALSE) 
```
Remember, if the P-value is small, what you're saying is the probability of observing a test statistic as extreme is low if the null hypothesis were true.We make lower.tail = false because we want the probability of being larger than 2.5, as or more extreme in the direction of the alternative. 

So the results say the probability of seeing evidence as or more extreme then actually obtained under the null hypothesis is around 1%, so either the null hypothesis is true, and we've seen an exceptionally large T statistic, or the null hypothesis is false.

Another way to think about the P-value, is its the smallest value for alpha for which you would still reject the null hypothesis, the `attained significance level`. And what this means is that the P-value is an extremely convenient test statistic to communicate to people, because when you give it to them, they can test it versus whatever alpha level they would like.

---
## The attained significance level
* Our test statistic was $2$ for $H_0 : \mu_0  = 30$ versus $H_a:\mu > 30$.
* Notice that we rejected the one sided test when $\alpha = 0.05$, would we reject if $\alpha = 0.01$, how about $0.001$?
* The smallest value for alpha that you still reject the null hypothesis is called the *attained significance level*
* This is equivalent, but philosophically a little different from, the *P-value*

---
## Notes
* By reporting a P-value the reader can perform the hypothesis
  test at whatever $\alpha$ level he or she choses
* If the P-value is less than $\alpha$ you reject the null hypothesis 
* For two sided hypothesis test, double the smaller of the two one
  sided hypothesis test Pvalues

---
## Revisiting an earlier example
- Suppose a friend has $8$ children, $7$ of which are girls and none are twins
- If each gender has an independent $50$% probability for each birth, what's the probability of getting $7$ or more girls out of $8$ births?
```{r}
choose(8, 7) * .5 ^ 8 + choose(8, 8) * .5 ^ 8 
pbinom(6, size = 8, prob = .5, lower.tail = FALSE)
```

Here , if we were testing that hypothesis, we would reject at a 5% level. We would reject at a 4% level, but we would not reject at an type 1 error rate of 3%. 

---
## Poisson example
- Suppose that a hospital has an infection rate of 10 infections per 100 person/days at risk (rate of 0.1) during the last monitoring period.
- Assume that an infection rate of 0.05 is an important benchmark. 
- Given the model, could the observed rate being larger than 0.05 be attributed to chance?
- Under $H_0: \lambda = 0.05$ so that $\lambda_0 100 = 5$
- Consider $H_a: \lambda > 0.05$.

```{r}
ppois(9, 5, lower.tail = FALSE)
```
The rate is 0.05 having been monitored for 100 person days at risk, is the probability of obtaining 10 or more infections. So in R we plug in (n-1) that is 9 for the upper tail, days at risk is 5 and lower.tail=FALSE because want 10 or more, not less than 10!

So the results show that there is only a 3% chance of that occurring. As the real infection was 5 for a 100 person days at risk, 5%, this hospital should perhaps should execute planned quality control procedures.


