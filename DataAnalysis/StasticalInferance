###########################################################################
We
| can assume normality of a sample mean no matter what kind of population
| we have, as long as our sample size is large enough and our samples are
| independent. 

the CENTRAL LIMIT THEOREM (CLT) -
| one of the most important theorems in all of statistics. It states that
| the distribution of averages of iid variables (properly normalized as 
 independent,identically distributed random variables from an infinite population
| with mean mu and variance sigma^2.)becomes that of a standard normal as the sample size increases.

We denote this as X'~N(mu,sigma^2/n).

| We know from the CLT that for large n, the sample mean is normal with
| mean mu and standard deviation sigma/sqrt(n). We also know that 95% of
| the area under a normal curve is within two standard deviations of the
| mean. This figure, a standard normal with mu=0 and sigma=1, illustrates
| this point; the entire shaded portion depicts the area within 2
| standard deviations of the mean and the darker portion shows the 68% of
| the area within 1 standard deviation. 

| As we've seen before, in a binomial distribution in which p represents the
| probability or proportion of success, the variance sigma^2 is p(1-p), so the
| standard error of the sample mean p' is sqrt(p(1-p)/n) where n is the sample size.
| The 95% confidence interval of p is then p' +/- 2*sqrt(p(1-p)/n). The 2 in this
| formula represents the approximate 97.5% normal quantile.

 Figure: stddev1.R
 
The sample variance estimates population variance.
The distribution of the sample variance is centered at the population variance.
The sample variance gets more concentrated around the population variance with 
larger sample sizes
The variance of the sample mean is the population variance divided by n.
The standard error of the sample mean is the sample standard deviation s divided 
by sqrt(n). 
The Central Limit Theorem (CLT) tells us that averages have normal distributions
| with standard deviations equal to  the standard error. So, To calculate a confidence interval for a mean you take the sample mean and add and
| subtract the relevant normal quantile times the standard error.


Common distributions are Bernoulli - binary trials, the Gaussian, it
forms a bell shaped curve, symmetric about its mean mu and the  the Poisson 
distribution models counts or number of event in some interval of time.

 A quick fix to the problem of having a small n is to use the Agresti/Coull interval.
| This simply means we add 2 successes and 2 failures to the counts when calculating
| the proportion p'.
###########################################################################

###########################################################################
| The sample standard deviation, s, tells us how variable the population
| is, and s/sqrt(n), the standard error, tells us how much averages of
| random samples of size n from the population vary:

###########################################################################

The standard deviation of a statistic is called its standard error, so
the standard error of the sample mean is the square root of its
variance.

 Var(X')
 =Var(1/n*Sum(X_i))
 =(1/n^2)*Var(Sum(X_i))
 =(1/n^2)*Sum(sigma^2)
 =sigma^2/n
 
for infinite populations when our samples are independent.

##its square root, s / sqrt(n), is the standard error of the sample mean.

###############NORMAL############################################################

> sd(apply(matrix(rnorm(10000),1000),1,mean))
[1] 0.3059331

1/sqrt(10) to see if it matches the standard
| deviation we just computed with our simulation.
> 1/sqrt(10)
[1] 0.3162278

| This returns the standard deviation of 1000 averages, each of a sample
| of 10 random normal numbers with mean 0 and standard deviation 1. The
| theory tells us that the standard error, s/sqrt(n), of the sample means
| indicates how much averages of random samples of size n (in this case
| 10) vary.

############POISSON##############################################################

> sd(apply(matrix(runif(10000),1000),1,mean))
[1] 0.09286037

>  1/sqrt(120)
[1] 0.09128709

Standard uniform
| distributions have variance 1/12. The theory tells us the standard
| error of means of independent samples of size n would have which
| standard errorof 1/sqrt(12*n). Poisson(4) are distributions with variance
| 4; with standard error would means of random samples of n Poisson(4)
| of 2/sqrt(n)

##assume you're
| taking averages of 10 Poisson(4) samples and compute the standard error
| of these means. 

> 2/sqrt(10)
[1] 0.6324555

> sd(apply(matrix(rpois(10000,4),1000),1,mean))
[1] 0.6324055

###########################################################################

 Fair coin flips have variance 0.25;
| means of random samples of n coin flips have what standard error of 
1/(2*sqrt(n)). 

> 1/(2*sqrt(10))
[1] 0.1581139
> sd(apply(matrix(sample(0:1,10000,TRUE),1000),1,mean))
[1] 0.1611111

taking averages of 10 coin flips and
| compute the standard error of these means

## Chebyshev's inequality###############################################"
helps
| interpret variances. It states that the probability that a random
| variable X is at least k standard deviations from its mean is less than
| 1/(k^2). In other words, the probability that X is at least 2 standard
| deviations from the mean is less than 1/4, 3 standard deviations 1/9, 4
| standard deviations 1/16, etc.

| However this estimate is quite conservative for random variables that
##| are normally distributed, that is, with bell-curve distributions. In
| these cases, the probability of being at least 2 standard deviations
| from the mean is about 5% (as compared to Chebyshev's upper bound of
| 25%) and the probability of being at least 3 standard deviations from
| the mean is roughly .2%.


######################################################################
 the Bernoulli is associated with experiments which have only 2 possible 
 outcomes. These are also called (by people in the know) binary trials.
#####################################################################

say that Bernoulli random variables take
| only the values 1 and 0. Suppose we also specify that the probability
| that the Bernoulli outcome of 1 is p. The following represents
| the probability of a 0 outcome: 
 1-p
 
 If the probability of a 1 is p and the probability of a 0 is 1-p 
 p^x *(1-p)^(1-x)
represents the PMF of a Bernoulli distribution? 
Recall
| that the PMF is the function representing the probability that X=x.

Suppose
| we have a Bernoulli random variable and, as before, the probability it
| equals 1 (a success) is p and probability it equals 0 (a failure) is
| 1-p. 

Its mean is p. 

| Given the same Bernoulli random variable above, p represents E(X^2)

So we can use the answers of the last two questions to find the variance of the
| Bernoulli random variable. 

Recall Var = E(X^2)-(E(X))^2
=  p(1-p)

| Binomial random variables are obtained as the sum of iid Bernoulli
| trials.  Specifically, let X_1, ..., X_n be iid Bernoulli(p) random
| variables; then X = X_1 + X_2 + ... X_n is a binomial random variable.
| Binomial random variables represent the number of successes, k, out of
| n independent Bernoulli trials. Each of the trials has probability p.

####### PMF of a a binomial random variable X ########################## 

| The PMF of a binomial random variable X is the function representing
| the probability that X=x. In other words, that there are x successes
| out of n independent trials. 

choose(n,x) * p^x * (1-p)^(n-x) represents the PMF
| of a binomial distribution? Here x, the number of successes, goes from
| 0 to n, the number of trials, and choose(n,x) represents the binomial
| coefficient 'n choose x' which is the number of ways x successes out of
| n trials can occur regardless of order.

 Suppose we were going to flip a biased coin 5 times. The probability of
| tossing a head is .8 and a tail .2. What is the probability that you'll
| toss at least 3 heads.

 add together 3 terms each of the form, choose(5,x)*(.8)^x*(.2)^(5-x) for x=3,4,5 
 
 > sum((choose(5,3)*(.8)^3*(.2)^(5-3))
 +(choose(5,4)*(.8)^4*(.2)^(5-4))
 +(choose(5,5)*(.8)^5*(.2)^(5-5))
 )
[1] 0.94208

> pbinom(2,size=5,prob=.8,lower.tail=FALSE)
[1] 0.94208

Now you can verify your answer with the R function pbinom. The quantile
| is 2, the size is 5, the prob is .8 and the lower.tail is FALSE.

##########################################################################
| Another very common distribution is the normal or Gaussian. It has a
| complicated density function involving its mean mu and variance
| sigma^2. The key fact of the density formula is that when plotted, it
| forms a bell shaped curve, symmetric about its mean mu. The variance
| sigma^2 corresponds to the width of the bell, the higher the variance,
| the fatter the bell. We denote a normally distributed random variable X
| as X ~ N(mu, sigma^2).
############################################################################

| When mu = 0 and sigma = 1 the resulting distribution is called the
| standard normal distribution and it is often labeled Z.

| Approximately 68%, 95% and 99% of the normal density lie within 1, 2
| and 3 standard deviations from the mean, respectively. These are shown
| in the three shaded areas of the figure. For example, the darkest
| portion (between -1 and 1) represents 68% of the area.

 The 10th percentile of the standard normal, is:
 > qnorm(.10)
[1] -1.281552

| We can use the symmetry of the bell curve to determine other quantiles.
| Given that 2.5% of the area under the curve falls to the left of
| x=-1.96, the 97.5 percentile for the standard normal is 1.96.

## If X is a
| normal random variable with mean mu and variance sigma^2, i.e., 
X ~ N(mu,sigma^2)

The converse is also true. If Z is standard normal, i.e., Z ~ N(0,1),
then  the random variable X defined as  X = mu + sigma*Z is normally
distributed with 
mean mu and variance sigma^2, i.e., 
X ~ N(mu, sigma^2) 

| These formulae allow you to easily compute quantiles (and thus
| percentiles) for ANY normally distributed variable if you know its mean
| and variance. We'll show how to find the 97.5th percentile of a normal
| distribution with mean 3 and variance 4.

> qnorm(.975,mean=3,sd=2)
[1] 6.919928

> 1.96*2 + 3
[1] 6.92
 
 ## R functions pnorm and qnorm are inverses
qnorm(pnorm(.53))= pnorm(qnorm(.53))=.53

Used R's qnorm function and simply specify the mean and
| standard deviation (the square root of the variance). Do this now. Find
| the 97.5th percentile of a normal distribution with mean 3 and standard
| deviation 2.
check it using the formula above, X = mu + sigma*Z.

########################################################################

| Suppose you have a normal distribution with mean 1020 and standard
| deviation of 50 and you want to compute the probability that the
| associated random variable X > 1200. The easiest way to do this is to
| use R's pnorm function in which you specify the quantile (1200), the
| mean (1020) and standard deviation (50). You also must specify that the
| lower.tail is FALSE since we're asking for a probability that the
| random variable is greater than our quantile. Do this now.

> pnorm(1200,mean=1020,sd=50,lower.tail=FALSE)
[1] 0.0001591086

| Alternatively, we could use the formula above to transform the given
| distribution to a standard normal. We compute the number of standard
| deviations the specified number (1200) is from the mean with Z = (X
| -mu)/sigma. This is our new quantile. We can then use the standard
| normal distribution and the default values of pnorm. Remember to
| specify that lower.tail is FALSE.  Do this now.

> pnorm((1200-1020)/50,lower.tail=FALSE)
[1] 0.0001591086


the 75% percentile: 
> qnorm(.75,mean=1020,sd=50)
[1] 1053.724


#######################################################################
| Now let's talk about our last common distribution, the Poisson. This
| is, as Wikipedia tells us, "a discrete probability distribution that
| expresses the probability of a given number of events occurring in a
| fixed interval of time and/or space if these events occur with a known
| average rate and independently of the time since the last event."
#######################################################################

| In other words, the Poisson distribution models counts or number of
| event in some interval of time. From Wikipedia, "Any variable that is
| Poisson distributed only takes on integer values."

| The PMF of the Poisson distribution has one parameter, lambda. As with
| the other distributions the PMF calculates the probability that the
| Poisson distributed random variable X takes the value x. Specifically,
| P(X=x)=(lambda^x)e^(-lambda)/x!. Here x ranges from 0 to infinity.
| The mean and variance of the Poisson distribution are both lambda.

| Poisson random variables are used to model rates such as the rate of
| hard drive failures. We write X~Poisson(lambda*t) where lambda is the
| expected count per unit of time and t is the total monitoring time.

| For example, suppose the number of people that show up at a bus stop is
| Poisson with a mean of 2.5 per hour, and we want to know the
| probability that at most 3 people show up in a 4 hour period. We use
| the R function ppois which returns a probability that the random
| variable is less than or equal to 3. We only need to specify the
| quantile (3) and the mean (2.5 * 4). We can use the default parameters,
| lower.tail=TRUE and log.p=FALSE. Try it now.

> ppois(3,2.5 * 4)
[1] 0.01033605

| Finally, the Poisson distribution approximates the binomial
| distribution in certain cases. Recall that the binomial distribution is
| the discrete distribution of the number of successes, k, out of n
| independent binary trials, each with probability p. If n is large and p
| is small then the Poisson distribution with lambda equal to n*p is a
| good approximation to the binomial distribution.

| To see this, use the R function pbinom to estimate the probability that
| you'll see at most 5 successes out of 1000 trials each of which has
| probability .01. As before, you can use the default parameter values
| (lower.tail=TRUE and log.p=FALSE) and just specify the quantile, size,
| and probability.

> pbinom(5,1000,.01)
[1] 0.06613951

| Now use the function ppois with quantile equal to 5 and lambda equal to
| n*p to see if you get a similar result.

> ppois(5,1000*.01)
[1] 0.06708596

This worked because n was
| large (1000) and p was small (.01).


###################################################################################
the CENTRAL LIMIT THEOREM (CLT) -
| one of the most important theorems in all of statistics. It states that
| the distribution of averages of iid variables (properly normalized)
| becomes that of a standard normal as the sample size increases.
##################################################################################

The mean of the sample mean estimates the population mean.

| The Law of Large Numbers (LLN) says that the average (mean) approaches
| what it's estimating. We saw in our simulations that the larger the
| sample size the better the estimation. 


| We say that an estimator is CONSISTENT if it converges to what it's
| trying to estimate. The LLN says that the sample mean of iid samples is
| consistent for the population mean. 

the sample variance (and hence sample deviation) are consistent

'properly normalized'
| means that you transformed the sample mean X'. You subtracted the
| population mean mu from it and divided the difference by sigma/sqrt(n).
| Here sigma is the standard deviation of the population and n is the
| sample size.

the CLT says that for large n, this normalized variable,
| (X'-mu)/(sigma/sqrt(n)) is almost normally distributed with mean 0 and
| variance 1. 

Remember that n must be large for the CLT to apply.

 Since the
| population std deviation sigma is unknown, sigma/sqrt(n) is often
| approximated by the standard error of the sample mean

| Let's rephrase the CLT. Suppose X_1, X_2, ... X_n are independent,
| identically distributed random variables from an infinite population
| with mean mu and variance sigma^2. Then if n is large, the mean of the
| X's, call it X', is approximately normal with mean mu and variance
| sigma^2/n. We denote this as 

############## X'~N(mu,sigma^2/n) ###############################


| Notice that the CLT said nothing about the original population being
| normally distributed. That's precisely where its usefulness lies! We
| can assume normality of a sample mean no matter what kind of population
| we have, as long as our sample size is large enough and our samples are
| independent. Let's look at how it works with a binomial experiment like
| flipping a coin.


| Recall that if the probability of a head (call it 1) is p, then the
| probability of a tail (0) is 1-p. The expected value then is p and the
| variance is p-p^2 or p(1-p). Suppose we do n coin flips and let p'
| represent the average of these n flips. We normalize p' by subtracting
| the mean p and dividing by the std deviation sqrt(p(1-p)/n). Let's do
| this for 1000 trials and plot the resulting histogram.

| We know from the CLT that for large n, the sample mean is normal with
| mean mu and standard deviation sigma/sqrt(n). We also know that 95% of
| the area under a normal curve is within two standard deviations of the
| mean. This figure, a standard normal with mu=0 and sigma=1, illustrates
| this point; the entire shaded portion depicts the area within 2
| standard deviations of the mean and the darker portion shows the 68% of
| the area within 1 standard deviation.

| It follows that 5% of the area under the curve is not shaded. By symmetry of the
| curve, only 2.5% of the data is greater than the mean + 2 standard deviations
| (mu+2*sigma/sqrt(n)) and only 2.5% is less than the mean - 2 standard deviations
| (mu-2*sigma/sqrt(n)).

| So the probability that the sample mean X' is bigger than mu + 2sigma/sqrt(n) OR
| smaller than mu-2sigma/sqrt(n) is 5%.  Equivalently, the probability of being
| between these limits is 95%. Of course we could have different sizes of intervals.
| If we wanted something other than 95, then we would use a quantile other than 2.

| The quantity X' plus or minus 2 sigma/sqrt(n) is called a 95% interval for mu. The
| 95% says that if one were to repeatedly get samples of size n, about 95% of the
| intervals obtained would contain mu, the quantity we're trying to estimate.

| Note that for a 95% confidence interval we divide (100-95) by 2 (since we have both
| left and right tails) and add the result to 95 to compute the quantile we need. The
| 97.5 quantile is actually 1.96, but for simplicity it's often just rounded up to 2.
| If you wanted to find a 90% confidence interval you would get the 95th quantile would you want?

> qnorm(.95)
[1] 1.644854

| As we've seen before, in a binomial distribution in which p represents the
| probability or proportion of success, the variance sigma^2 is p(1-p), so the
| standard error of the sample mean p' is sqrt(p(1-p)/n) where n is the sample size.
| The 95% confidence interval of p is then p' +/- 2*sqrt(p(1-p)/n). The 2 in this
| formula represents the approximate 97.5% normal quantile.

| A critical point here is that we don't know the true value of p; that's what we're
| trying to estimate. How can we compute a confidence interval if we don't know
| p(1-p)? We could be conservative and try to maximize it so we get the largest
| possible confidence interval. Calculus tells us that p(1-p) is maximized when p=1/2,
| so we get the biggest 95% confidence interval when we set p=1/2 in the formula p'+/-
| 2*sqrt(p(1-p)/n).

| Using 1/2 for the value of p in the formula above yields what expression for the 95%
| confidence interval for p?

 p'+/- 1/sqrt(n)
 
 | Here's another example of applying this formula from the slides. Suppose you were
| running for office and your pollster polled 100 people. Of these 60 claimed they
| were going to vote for you. You'd like to estimate the true proportion of people who
| will vote for you and you want to be 95% confident of your estimate. We need to find
| the limits that will contain the true proportion of your supporters with 95%
| confidence, so we'll use the formula p' +/- 1/sqrt(n) to answer this question.
| First, what value would you use for p', the sampled estimate?
.60

 use for 1/sqrt(n) = 1/sqrt(100) = 1/10 =.1
 
We know p'- 1/sqrt(n) is the lower bound and p'+ 1/sqrt(n) is the upper bound, so use the answers from the two previous answers to fill in values for these variables.
 
 | The bounds of the interval then are:
 
.60  +/- .1 is (.5 and .7)

| With 95% confidence, between .5 and .7 of the voters support you. You look like a
| winner to me!

##the Wald confidence interval##
  |===============================                                 |  48%
| Another technique for calculating confidence intervals for binomial distributions is
| to replace p with p'. This is called the Wald confidence interval. We can also use
| the R function qnorm to get a more precise quantile value (closer to 1.96) instead
| of our ballpark estimate of 2.
| With the formula p'+/- qnorm(.975)*sqrt(p'(1-p')/100), use the p' and n values from
| above and the R construct p'+c(-1,1)... to handle the plus/minus portion of the
| formula. You should see bounds similar to the ones you just estimated.

> .6 + c(-1,1)*qnorm(.975)*sqrt(.6*.4/100)
[1] 0.5039818 0.6960182

| As an alternative to this Wald interval, we can also use the R function binom.test
| with the parameters 60 and 100 and let all the others default. This function
| "performs an exact test of a simple null hypothesis about the probability of success
| in a Bernoulli experiment." (This means it guarantees the coverages, uses a lot of
| computation and doesn't rely on the CLT.) This function returns a lot of information
| but all we want now are the values of the confidence interval that it returns. Use
| the R construct x$conf.int to find these now.

> binom.test(60,100)$conf.int
[1] 0.4972092 0.6967052
attr(,"conf.level")
[1] 0.95

the Wald interval isn't very accurate when n is small. 

n <- 20
nosim <- 30
mywald <- function(p){
  phats <- rbinom(nosim, prob = p, size = n) / n
  ll <- phats - qnorm(.975) * sqrt(phats * (1 - phats) / n)
  ul <- phats + qnorm(.975) * sqrt(phats * (1 - phats) / n)
  print("Here are the p\' values")
  print(phats)
  print("Here are the lower")
  print(ll)
  print("Here are the upper")
  print(ul)
  mean(ll < p & ul > p)
}

> mywald(.2)
[1] "Here are the p' values"
 [1] 0.25 0.25 0.20 0.20 0.15 0.30 0.05 0.10 0.25 0.15 0.20 0.20 0.25 0.30 0.20 0.15
[17] 0.20 0.25 0.15 0.35 0.20 0.30 0.35 0.30 0.15 0.10 0.05 0.15 0.05 0.20
[1] "Here are the lower"
 [1]  0.060227303  0.060227303  0.024695492  0.024695492 -0.006490575  0.099163455
 [7] -0.045516829 -0.031478381  0.060227303 -0.006490575  0.024695492  0.024695492
[13]  0.060227303  0.099163455  0.024695492 -0.006490575  0.024695492  0.060227303
[19] -0.006490575  0.140962697  0.024695492  0.099163455  0.140962697  0.099163455
[25] -0.006490575 -0.031478381 -0.045516829 -0.006490575 -0.045516829  0.024695492
[1] "Here are the upper"
 [1] 0.4397727 0.4397727 0.3753045 0.3753045 0.3064906 0.5008365 0.1455168 0.2314784
 [9] 0.4397727 0.3064906 0.3753045 0.3753045 0.4397727 0.5008365 0.3753045 0.3064906
[17] 0.3753045 0.4397727 0.3064906 0.5590373 0.3753045 0.5008365 0.5590373 0.5008365
[25] 0.3064906 0.2314784 0.1455168 0.3064906 0.1455168 0.3753045
[1] 0.9



usually the only probability that hits close to or above the 95% line is
| the p=.5 . So this shows that when n, the number of flips, is small (20) the CLT
| doesn't hold for many values of p, so the Wald interval doesn't work very well.

| Let's try the same experiment and increase n, the number of coin flips in each of
| our 1000 trials, from 20 to 100 to see if the plot improves. Again, results may
| vary, but all the probabilities are much closer to the 95% line, so the CLT works
| better with a bigger value of n.

#########Agresti/Coull interval.#########
| A quick fix to the problem of having a small n is to use the Agresti/Coull interval.
| This simply means we add 2 successes and 2 failures to the counts when calculating
| the proportion p'. Specifically, if X is the number of successes out of the 20 coin
| flips, then instead of setting p'=X/20, let p'=(X+2)/24. We use 24 as the number of
| trials since we've added 2 successes and 2 failures to the counts. Note that we
| still use 20 in the calculation of the upper and lower bounds.

| Here's a plot using this Agresti/Coull interval, with 1000 trials of 20 coin flips
| each. It looks much better than both the original Wald with 20 coin flips and the
| improved Wald with 100 coin flips. However, this technique might make the confidence
| interval too wide.

####EXAMPLE
| To show this simply, we wrote a function ACCompar, which takes an integer input n.

ACCompar <- function(n){
 num <- 1:n 
 den <- n
 nn <- num+2
 nd <- den+4
 nf <- nn/nd
 of <- num/den
 scor <- nf<of
 print(scor)
 sum(scor)
}

| For each k from 1 to n it computes two fractions, k/n and (k+2)/(n+4). It then
| prints out the boolean vector of whether the new (k+2)/(n+4) fraction is less than
| the old k/n. It also prints out the total number of k's for which the condition is
| TRUE.

| For all k less than n/2, you see FALSE indicating that the new fraction is greater
| than or equal to k/n. For all k greater than n/2 you see TRUE indicating that the
| new fraction is less than the old. If k=n/2 the old and new fractions are equal.

> ACCompar(20)
 [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE
[14]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE
[1] 10


################## Poisson distributions and confidence intervals#############
| Let's move on to Poisson distributions and confidence intervals. Recall that Poisson
| distributions apply to counts or rates. For the latter, we write X~Poisson(lambda*t)
| where lambda is the expected count per unit of time and t is the total monitoring
| time.
| Here's another example from the slides. Suppose a nuclear pump failed 5 times out of
| 94.32 days and we want a 95% confidence interval for the failure rate per day. The
| number of failures X is Poisson distributed with parameter (lambda*t). We don't
| observe the failure rate, but we estimate it as x/t. Call our estimate lambda_hat,
| so lambda_hat=x/t. According to theory, the variance of our estimated failure rate
| is lambda/t. Again, we don't observe lambda, so we use our estimate of it instead.
| We thus approximate the variance of lambda_hat as lambda_hat/t.

In this example what would you use 5/94.32 as the estimated mean x/t

lamb <- 5/94.32

| So lamb is our estimated mean and lamb/t is our estimated variance. The formula
| we've used to calculate a 95% confidence interval is est mean +
| c(-1,1)*qnorm(.975)*sqrt(est var). Use this formula now making the appropriate
| substitutions.

> lamb +c(-1,1)*qnorm(.975)*sqrt(lamb/94.32)
[1] 0.006545667 0.099476386

| As a check we can use R's function poisson.test with the arguments 5 and 94.32 to
| check this result. This is an exact test so it guarantees coverage. As with the
| binomial exact test, we only need to look at the conf portion of the result using
| the x$conf construct. Do this now.

> poisson.test(5,94.32)$conf
[1] 0.01721254 0.12371005
attr(,"conf.level")
[1] 0.95


| Pretty close, right? Now to check the coverage of our estimate we'll run the same
| simulation experiment we ran before with binomial distributions. We'll vary our
| lambda values from .005 to .1 with steps of .01 (so we have 10 of them), and for
| each one we'll generate 1000 Poisson samples with mean lambda*t. We'll calculate
| sample means and use them to compute 95% confidence intervals. We'll then count how
| often out of the 1000 simulations the true mean (our lambda) was contained in the
| computed interval.

  |==================================================              |  78%
| Here's a plot of the results. We see that the coverage improves as lambda gets
| larger, and it's quite off for small lambda values.



